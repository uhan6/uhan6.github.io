---
title: '数据同步工具的正确打开方式'
category: ETL 
tags: [ETL]
---
## 前言 
随着业务的发展必然导致数据量的增大，同时大量的数据也拥有丰富的价值。在对大量数据的处理中不可避免的会面对多个、多层级的数据库的数据同步问题。在数据同步中我先是接触到了Informatica同步工具，之后又接触并使用Azure Data Factory开发了同步任务。在使用两者的过程中总结了一些经验和教训。

## 1. 同步工具只负责数据同步

对于Informatica和ADF，这两个工具都是支持对数据转换的操作的。比如对于Informatica，我们可以对数据源的表进行join，对字段使用内置的函数转大小写、切分等等。而ADF也有数据处理的函数。 

我认为对于ETL任务来讲，同步工具应该只负责对数据进行同步，我们不应该过分依赖于同步工具的对数据的转换处理。

我们在一开始开发数据仓库的过程中，我们把数据分层切割以后，会有一些计算逻辑需要实现。我们使用了数据库视图和存储过程来计算数据，在数据量和计算逻辑不复杂的情况下，这样的做法就避免引入了专门的计算单元而实现了计算。但是随着数据量的增大和新需求导致计算逻辑的猛增，使数据库存储过程不仅开发起来不方便，而且导致后续的维护出现很大的麻烦。

所以对于数据的计算，最好还是使用专门的计算层来对数据进行计算，而同步工具的转换或者数据库的存储过程，只是工具糖而已，不应该把主要的计算逻辑放到数据库和同步工具。

## 2. 尽量使用工具的原生功能

由于业务的需要，我们将数据同步和数据计算的功能由原本的Informatica迁移到了ADF。在Informatica中，我们有一个非常常用的功能：获取单个任务的上次运行时间。我们对数据的同步任务，大部分都是增量同步的，所以要获取上次运行时间来筛选出这段时间内的增量数据。而ADF是没有这个功能的，我们查阅了官方文档发现官方对于增量也是采取了替代方法的。于是我们在一张表里记录所有任务的名称和上次运行时间，并在任务开始时读取时间来获取增量区间。而对增量任务又需要防止上次任务没有运行完，导致同时增量使目标表插入重复数据。在Informatica中，任务触发时若检测到上一个在运行则会停止当前任务。

所以在选取数据同步工具的时候，对于一些比较常用而没有的功能，要考虑自己开发会带来的额外任务量和不稳定的情况。

## 3. 保障数据的准确性

对于数据同步工具来讲，要保证拷贝的数据能准确的到目标表需要花费较多的心思。以下几点是在实际中遇到的问题：

1. 同个任务在同一时间并行运行，会导致数据重复拷贝。
2. 数据表结构的变更导致新增的字段是否能被同步。
3. 如果存在脏数据是否会处理并记录下来。
4. 因为突发情况导致的程序崩溃是否会导致数据重复。

为了应对这些问题，我们会有对出错的记录并开启邮件报警，在遇到问题时还需要人工进行排查。所以在使用同步工具时，数据准确性是一个不得不考虑的问题。

## 总结

数据同步工具总是会伴随ETL工具出现，在使用数据同步工具的过程中应该保持独立性的原则，不应该让太多的业务计算去污染单纯的同步工具的使用。同时对于保障数据准确性来讲，数据同步工具仍需要花费人力来进行出错排查，在开发过程中若能保证同步的可覆盖性，对于错误处理会省更多的时间。

